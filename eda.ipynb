{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](https://lms.skillfactory.ru/assets/courseware/v1/824479af6a8c599b5138ae967c573e24/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-eda-1-2.png) <br/><br/>\n",
    "![](https://lms.skillfactory.ru/assets/courseware/v1/1470f05621fde7ab0edeee9fcae6ee19/asset-v1:SkillFactory+DST-3.0+28FEB2021+type@asset+block/dst-eda-1-1.png) <br/><br/>\n",
    "\n",
    "## Methods\n",
    "[1. FEATURE ENGINEERING](#feature-engineering)<br>\n",
    "[2. FEATURE SELECTION](#feature-selection)<br>\n",
    "[3. FEATURE ENCODING](#feature-encoding)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy  as np\n",
    "import category_encoders as ce\n",
    "\n",
    "import statistics\n",
    "from sklearn import preprocessing\n",
    "from scipy import stats\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas_profiling import ProfileReport\n",
    "import dtale\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./Data/wine.csv\")\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# d = dtale.show(data)\n",
    "# d\n",
    "# profile = ProfileReport(data)\n",
    "# profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of tasters: {data['taster_name'].value_counts().count()}\")\n",
    "print(f\"Max bottle price:  {data['price'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = list(data.columns)\n",
    "mask    = data.duplicated(subset=columns)\n",
    "\n",
    "duplicates = data[mask]\n",
    "print(f\"Number of duplicates: {duplicates.shape[0]}\")\n",
    "\n",
    "data_dup = data.drop_duplicates(subset=columns)\n",
    "print(f\"Number of rows with duplicates removed: {data_dup.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data_dup.isnull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_drop = data_dup.copy()\n",
    "\n",
    "thresh    = data_drop.shape[0] * 0.7\n",
    "data_drop = data_drop.dropna(how='any', thresh=thresh, axis=1)\n",
    "\n",
    "data_drop['designation'] = data_drop['designation'].fillna('unknown')\n",
    "data_drop['region_1'] = data_drop['region_1'].fillna('unknown')\n",
    "data_drop['taster_name'] = data_drop['taster_name'].fillna('unknown')\n",
    "data_drop['taster_twitter_handle'] = data_drop['taster_twitter_handle'].fillna('unknown')\n",
    "\n",
    "data_drop['country'] = data_drop['country'].fillna('US')\n",
    "data_drop['price'] = data_drop['price'].fillna(data_drop['price'].mean())\n",
    "data_drop['province'] = data_drop['province'].fillna('California')\n",
    "data_drop['variety'] = data_drop['variety'].fillna('Pinot Noir')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics & EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./Data/wine_cleared.csv')\n",
    "data.drop('Unnamed: 0', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Min points:   {data['points'].min()}\")\n",
    "print(f\"Min price:    {data['price'].min()}\")\n",
    "print(f\"Mean price:   {round(statistics.mean(data['price']), 2)}\")\n",
    "print(f\"Median price: {round(statistics.median(data['price']), 2)}\")\n",
    "print(f\"Mode price:   {round(statistics.mode(data['price']), 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median\n",
    "# lst = sorted(data['price'])\n",
    "# mid  = len(lst) // 2\n",
    "# median = (lst[mid] + lst[~mid]) / 2\n",
    "\n",
    "# Mode\n",
    "# freq = {}\n",
    "# for price in data['price']:\n",
    "#     if price in freq:\n",
    "#         freq[price] += 1\n",
    "#     else:\n",
    "#         freq.setdefault(price, 1)\n",
    "# print(max(freq, key=freq.get))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2)\n",
    "\n",
    "stats.probplot(data['price'], plot=ax1)\n",
    "ax2.hist(data['price'])\n",
    "\n",
    "stats.probplot(data['points'], plot=ax3)\n",
    "ax4.hist(data['points'])\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The correlation between continuous features that have a distribution close to normal can be calculated using the standard Pearson correlation.\n",
    "data.corr() # Pearson Corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spearman's correlation coefficient is used to calculate the relationships between categorical variables.\n",
    "data.corr(method='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Kendall's correlation coefficient is used to calculate the relationships between categorical variables.\n",
    "data.corr(method='kendall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "\n",
    "# Matthews correlation coefficient is used to calculate the relationships between binary categorical variables.\n",
    "x = [+1, -1, +1, +1] \n",
    "y = [+1, +1, +1, -1]\n",
    "matthews_corrcoef(x, y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_round'] = data['price'].round().astype(int)\n",
    "\n",
    "data['year'] = data['title'].str.findall('\\d{4}').str.get(0)\n",
    "data['year'] = pd.to_datetime(data['year'], errors='coerce')\n",
    "\n",
    "data['locality'] = data['title'].str.findall('\\((.*?)\\)').str.get(0)\n",
    "\n",
    "data['is_usa']    = data['country'].apply(lambda x: 1 if x == 'US' else 0)\n",
    "data['is_italy']  = data['country'].apply(lambda x: 1 if x == 'Italy' else 0)\n",
    "data['is_france'] = data['country'].apply(lambda x: 1 if x == 'France' else 0)\n",
    "\n",
    "data['old_wine'] = data['year'].apply(lambda x: 1 if x.year < 2010 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "population = pd.read_csv('Data/country_population.csv', sep=';')\n",
    "data = data.join(population.set_index('country'), on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area = pd.read_csv('Data/country_area.csv', sep=';')\n",
    "data = data.join(area.set_index('country'), on='country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['years_diff'] = (pd.to_datetime('2022-01-12')  - data['year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ordinal\n",
    "If the attribute to be encoded is ordinal, use Ordinal Encoding.<br><br>\n",
    "![](https://i.ibb.co/1b1b8WP/dst-eda-3-9.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clothing_list = [\n",
    "    ['xxs', 'dress'],\n",
    "    ['xxs', 'skirt'],\n",
    "    ['xs', 'dress'],\n",
    "    ['s', 'skirt'],\n",
    "    ['m', 'dress'],\n",
    "    ['l', 'shirt'],\n",
    "    ['s', 'coat'],\n",
    "    ['m', 'coat'],\n",
    "    ['xxl', 'shirt'],\n",
    "    ['l', 'dress']\n",
    "]\n",
    "\n",
    "clothing = pd.DataFrame(clothing_list, columns = ['size',  'type'])\n",
    "\n",
    "ord_encoder = ce.OrdinalEncoder(cols=['size'])\n",
    "data_bin = ord_encoder.fit_transform(clothing['size'])\n",
    "clothing = pd.concat([clothing, data_bin], axis=1)\n",
    "\n",
    "clothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One Hot\n",
    "For nominal attributes, the number of unique attribute values is important, since with a large number of them, memory problems may occur. If the attribute has less than 15 values, One Hot Encoding should be selected for the data. The number 15 is chosen empirically â€” for your dataset, this number can be 20 or 10. It depends on the number of features in your dataset, the number of rows, and many other factors. If there are few features, then you can also use One Hot coding.<br><br>\n",
    "![](https://i.ibb.co/HGZw1Yw/dst-eda-3-11.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols=['type'], use_cat_names=True)\n",
    "type_bin = encoder.fit_transform(clothing['type'])\n",
    "clothing = pd.concat([clothing, type_bin], axis=1)\n",
    "\n",
    "clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols=['taster_name'], use_cat_names=True)\n",
    "taster_bin = encoder.fit_transform(data['taster_name'])\n",
    "data = pd.concat([data, taster_bin], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary\n",
    "![](https://i.ibb.co/FwX5gYZ/dst-eda-3-14-copy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin_encoder = ce.BinaryEncoder(cols=['type'])\n",
    "type_bin = bin_encoder.fit_transform(clothing['type'])\n",
    "clothing = pd.concat([clothing, type_bin], axis=1)\n",
    "\n",
    "clothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.BinaryEncoder(cols=['country', 'taster_twitter_handle'])\n",
    "bin = encoder.fit_transform(data[['country', 'taster_twitter_handle']])\n",
    "data = pd.concat([data, bin], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalization & Standardization\n",
    "Instructions for converting features:\n",
    "\n",
    "- if the attribute is distributed normally, then it needs to be standardized;\n",
    "- if the attribute is distributed abnormally, it must be normalized;\n",
    "- if the spread of values is small, then you can do without data conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mm_scaler = preprocessing.MinMaxScaler()\n",
    "rb_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "mm_data = mm_scaler.fit_transform(data[['price']])\n",
    "rb_data = rb_scaler.fit_transform(data[['price']])\n",
    "\n",
    "data['price_mm_scaled'] = pd.DataFrame(mm_data)\n",
    "data['price_rb_scaled'] = pd.DataFrame(rb_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_scaler = preprocessing.StandardScaler()\n",
    "\n",
    "s_data = s_scaler.fit_transform(data[['price']])\n",
    "\n",
    "data['price_s_scaled'] = pd.DataFrame(s_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['price_s_scaled'][129968]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 24))\n",
    "axes = fig.add_axes([0, 0, 1, 1])\n",
    "axes = sns.heatmap(data.corr(), annot = True, fmt='.2g', vmin=-1, vmax=1, center=0, square=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(['is_usa', 'is_france', 'is_italy', 'price_round', 'area'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datav = pd.read_csv('Data/model.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "axes = fig.add_axes([0, 0, 1, 1])\n",
    "axes = sns.heatmap(datav.corr(), annot = True, fmt='.2g', vmin=-1, vmax=1, center=0, square=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 6))\n",
    "axes = fig.add_axes([0, 0, 1, 1])\n",
    "axes = sns.scatterplot(data=datav, x=\"Waist/Hip\", y=\"Waist\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(datav)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart = pd.read_csv('Data/heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trestbps(row):\n",
    "    age = row['age']\n",
    "    sex = row['sex']\n",
    "    trestbps_mean = np.NaN\n",
    "    \n",
    "    if age <= 20:\n",
    "        trestbps_mean = 123 if sex == 1 else 116\n",
    "    elif age <= 30:\n",
    "        trestbps_mean = 126 if sex == 1 else 120\n",
    "    elif age <= 40:\n",
    "        trestbps_mean = 129 if sex == 1 else 127\n",
    "    elif age <= 50:\n",
    "        trestbps_mean = 135 if sex == 1 else 137\n",
    "    elif age <= 60:\n",
    "        trestbps_mean = 142 if sex == 1 else 144\n",
    "    else:\n",
    "        trestbps_mean = 142 if sex == 1 else 115916\n",
    "    return trestbps_mean\n",
    "\n",
    "heart['old'] = heart['age'].apply(lambda v: 1 if v > 60 else 0)\n",
    "heart['trestbps_mean'] = heart.apply(get_trestbps, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = ce.OneHotEncoder(cols=['cp', 'restecg', 'slope', 'ca', 'thal'])\n",
    "bin = encoder.fit_transform(heart[['cp', 'restecg', 'slope', 'ca', 'thal']])\n",
    "heart = pd.concat([heart, bin], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rb_scaler = preprocessing.RobustScaler()\n",
    "\n",
    "rb_data = rb_scaler.fit_transform(heart[['age', 'trestbps', 'chol', 'oldpeak', 'thalach']])\n",
    "\n",
    "heart.drop(columns=['age', 'trestbps', 'chol', 'oldpeak', 'thalach'], axis=1, inplace=True)\n",
    "scaled = pd.DataFrame(rb_data, columns=['age', 'trestbps', 'chol', 'oldpeak', 'thalach'])\n",
    "\n",
    "heart = pd.concat([heart, scaled], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(40, 24))\n",
    "axes = fig.add_axes([0, 0, 1, 1])\n",
    "axes = sns.heatmap(heart.corr(), annot = True, fmt='.2g', vmin=-1, vmax=1, center=0, square=True)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "005d508735c64ef2549a4285bde8b924c2e8283ea6a839e46d9c1db76ebd1f6a"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('sf')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
